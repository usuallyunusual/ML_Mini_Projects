\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Machine Learning Lab 2}{1}{section.1}\protected@file@percent }
\newlabel{machine-learning-lab-2}{{1}{1}{Machine Learning Lab 2}{section.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Importing libraries for entire exercise}{1}{subsection.1.1}\protected@file@percent }
\newlabel{importing-libraries-for-entire-exercise}{{1.1}{1}{Importing libraries for entire exercise}{subsection.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Naive Bayes Classification on numeric data}{1}{section.2}\protected@file@percent }
\newlabel{naive-bayes-classification-on-numeric-data}{{2}{1}{Naive Bayes Classification on numeric data}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Loading data}{1}{subsection.2.1}\protected@file@percent }
\newlabel{loading-data}{{2.1}{1}{Loading data}{subsection.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Defining function to convert classes to numeric}{1}{subsection.2.2}\protected@file@percent }
\newlabel{defining-function-to-convert-classes-to-numeric}{{2.2}{1}{Defining function to convert classes to numeric}{subsection.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Applying conversion to entire dataframe and also preparing output vector}{2}{subsection.2.3}\protected@file@percent }
\newlabel{applying-conversion-to-entire-dataframe-and-also-preparing-output-vector}{{2.3}{2}{Applying conversion to entire dataframe and also preparing output vector}{subsection.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Splitting data and test and train sets (75-train and 25 test)}{2}{subsection.2.4}\protected@file@percent }
\newlabel{splitting-data-and-test-and-train-sets-75-train-and-25-test}{{2.4}{2}{Splitting data and test and train sets (75-train and 25 test)}{subsection.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Setting up Naive Bayes classifier to classify whether tumor is benign or malignant}{2}{subsection.2.5}\protected@file@percent }
\newlabel{setting-up-naive-bayes-classifier-to-classify-whether-tumor-is-benign-or-malignant}{{2.5}{2}{Setting up Naive Bayes classifier to classify whether tumor is benign or malignant}{subsection.2.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.1}We have to assume that the distribution of the data is Gaussian for the classifier to work (Hence the `Naive')}{2}{subsubsection.2.5.1}\protected@file@percent }
\newlabel{we-have-to-assume-that-the-distribution-of-the-data-is-gaussian-for-the-classifier-to-work-hence-the-naive}{{2.5.1}{2}{We have to assume that the distribution of the data is Gaussian for the classifier to work (Hence the `Naive')}{subsubsection.2.5.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.2}To this end we have used GuassianNB( ) function}{2}{subsubsection.2.5.2}\protected@file@percent }
\newlabel{to-this-end-we-have-used-guassiannb-function}{{2.5.2}{2}{To this end we have used GuassianNB( ) function}{subsubsection.2.5.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Error Metric 1: Accuracy}{2}{subsection.2.6}\protected@file@percent }
\newlabel{error-metric-1-accuracy}{{2.6}{2}{Error Metric 1: Accuracy}{subsection.2.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}Error Metric 2: Precision}{2}{subsection.2.7}\protected@file@percent }
\newlabel{error-metric-2-precision}{{2.7}{2}{Error Metric 2: Precision}{subsection.2.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.7.1}Introduced the confusion matrix that is essential to calculate the necessary metrics}{2}{subsubsection.2.7.1}\protected@file@percent }
\newlabel{introduced-the-confusion-matrix-that-is-essential-to-calculate-the-necessary-metrics}{{2.7.1}{2}{Introduced the confusion matrix that is essential to calculate the necessary metrics}{subsubsection.2.7.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8}Error Metric 3: Recall}{3}{subsection.2.8}\protected@file@percent }
\newlabel{error-metric-3-recall}{{2.8}{3}{Error Metric 3: Recall}{subsection.2.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9}Error Metric 4: F1 score (The most accurate metric to decide on how well the model is doing}{3}{subsection.2.9}\protected@file@percent }
\newlabel{error-metric-4-f1-score-the-most-accurate-metric-to-decide-on-how-well-the-model-is-doing}{{2.9}{3}{Error Metric 4: F1 score (The most accurate metric to decide on how well the model is doing}{subsection.2.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Plotting error metrics}{3}{section.3}\protected@file@percent }
\newlabel{plotting-error-metrics}{{3}{3}{Plotting error metrics}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Plot 1: Precision vs Recall}{3}{subsection.3.1}\protected@file@percent }
\newlabel{plot-1-precision-vs-recall}{{3.1}{3}{Plot 1: Precision vs Recall}{subsection.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Plot 2: The confusion matrix}{4}{subsection.3.2}\protected@file@percent }
\newlabel{plot-2-the-confusion-matrix}{{3.2}{4}{Plot 2: The confusion matrix}{subsection.3.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Naive Bayes classification on Nominal data}{4}{section.4}\protected@file@percent }
\newlabel{naive-bayes-classification-on-nominal-data}{{4}{4}{Naive Bayes classification on Nominal data}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Loading data from sklearn}{4}{subsection.4.1}\protected@file@percent }
\newlabel{loading-data-from-sklearn}{{4.1}{4}{Loading data from sklearn}{subsection.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Selecting specific categories as features and splitting data and test and train sets}{4}{subsection.4.2}\protected@file@percent }
\newlabel{selecting-specific-categories-as-features-and-splitting-data-and-test-and-train-sets}{{4.2}{4}{Selecting specific categories as features and splitting data and test and train sets}{subsection.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Preview of the data}{4}{subsection.4.3}\protected@file@percent }
\newlabel{preview-of-the-data}{{4.3}{4}{Preview of the data}{subsection.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Setting up Naive Bayes classification to classify into what category of news it is}{5}{subsection.4.4}\protected@file@percent }
\newlabel{setting-up-naive-bayes-classification-to-classify-into-what-category-of-news-it-is}{{4.4}{5}{Setting up Naive Bayes classification to classify into what category of news it is}{subsection.4.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.1}We first vectorize the articles using tf-idf that creates a feature vector oout of the frequency of words in an article}{5}{subsubsection.4.4.1}\protected@file@percent }
\newlabel{we-first-vectorize-the-articles-using-tf-idf-that-creates-a-feature-vector-oout-of-the-frequency-of-words-in-an-article}{{4.4.1}{5}{We first vectorize the articles using tf-idf that creates a feature vector oout of the frequency of words in an article}{subsubsection.4.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Predicting class labels}{6}{subsection.4.5}\protected@file@percent }
\newlabel{predicting-class-labels}{{4.5}{6}{Predicting class labels}{subsection.4.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Error metric 1: Accuracy}{6}{subsection.4.6}\protected@file@percent }
\newlabel{error-metric-1-accuracy}{{4.6}{6}{Error metric 1: Accuracy}{subsection.4.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7}Error Metric 2: Precision}{6}{subsection.4.7}\protected@file@percent }
\newlabel{error-metric-2-precision}{{4.7}{6}{Error Metric 2: Precision}{subsection.4.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.7.1}Introduced the confusion matrix that is essential to calculate the necessary metrics}{6}{subsubsection.4.7.1}\protected@file@percent }
\newlabel{introduced-the-confusion-matrix-that-is-essential-to-calculate-the-necessary-metrics}{{4.7.1}{6}{Introduced the confusion matrix that is essential to calculate the necessary metrics}{subsubsection.4.7.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8}Error Metric 3: Recall}{6}{subsection.4.8}\protected@file@percent }
\newlabel{error-metric-3-recall}{{4.8}{6}{Error Metric 3: Recall}{subsection.4.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9}Error Metric 4: F1 Score}{7}{subsection.4.9}\protected@file@percent }
\newlabel{error-metric-4-f1-score}{{4.9}{7}{Error Metric 4: F1 Score}{subsection.4.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Plotting error metrics}{7}{section.5}\protected@file@percent }
\newlabel{plotting-error-metrics}{{5}{7}{Plotting error metrics}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Plot 1: Confusion matrix}{7}{subsection.5.1}\protected@file@percent }
\newlabel{plot-1-confusion-matrix}{{5.1}{7}{Plot 1: Confusion matrix}{subsection.5.1}{}}
